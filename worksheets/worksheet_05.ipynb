{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name: Stone Harris\n",
    "UID: U41533031\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize the centroids [0, 2].\n",
    "2. Assign each data point to the nearest centroid: Points closer to 0: [0, 0.5, 1.5] ; Points closer to 2: [2, 6, 6.5, 7]\n",
    "3. Recompute centroids: New 1: Average of [0, 0.5, 1.5] = (0+0.5+1.5)/3 = 0.67 New 2: Average of [2, 6, 6.5, 7] = (2+6+6.5+7)/4 = 5.38\n",
    "4. Repeat: New points closer to 0.67: [0, 0.5, 1.5, 2] New points closer to 5.38: [6, 6.5, 7]\n",
    "5. Recompute centroids again: New 1: Average of [0, 0.5, 1.5, 2] = 1 ; New 2: Average of [6, 6.5, 7] = 6.5\n",
    "6. Could keep going, just repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-means cost function is basically how we score how good our clustering is. It adds up all the distances from each point to the center of its cluster; we want this score to be as low as possible because it means all the points in a cluster are bunched up close to the center, not scattered all over the place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different solutions to the K-means algorithm can occur because it often starts with random cluster centers. So based on where these initial centers are placed, the algorithm might group the data points differently each time it's run, leading to varied clustering results for the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lloyd's algorithm usually converges to a solution because it iteratively optimizes the cluster assignments and centroids, but it might not find the optimal clustering due to local minima. It doesn't necessarily guarantee the best solution though."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "    \n",
    "    def is_unassigned(self):\n",
    "        return self.assignment[1] == -1\n",
    "        \n",
    "    def unassign_all(self):\n",
    "        self.assignment = [-1 for _ in range(len(self.data))]\n",
    "\n",
    "    def dist(self, x, y):\n",
    "        return sum((x - y)**2) ** (1/2)\n",
    "    \n",
    "    \n",
    "    def initialize(self):\n",
    "        return self.data[np.random.choice(len(self.data), size=self.k, replace=False)]\n",
    "    \n",
    "    def are_centers_diff(self, c1, c2):\n",
    "       for i in range(len(c1)):\n",
    "           if c1[i] in c2:\n",
    "                return True\n",
    "       return False\n",
    "    \n",
    "    def assign(self):\n",
    "        for i in range(len(self.data)):\n",
    "            self.assignment[i] = 0\n",
    "            temp_dist = self.dist(self.data[i], centers[0])\n",
    "            for j in range(1, len(centers)):\n",
    "                new_dist = self.dist(self.data[i], centers[j])\n",
    "                if new_dist < temp_dist:\n",
    "                    self.assignment[i] = j\n",
    "                    temp_dist = new_dist\n",
    "\n",
    "    def calculate_new_centers(self):\n",
    "        centers = []\n",
    "        for j in range(self.k):\n",
    "            cluster_j = self.data[\n",
    "                np.array([i for i in range(len(self.data)) if self.assignment[i] == j])\n",
    "            ]\n",
    "            centers.append(np.mean(cluster_j))\n",
    "        return\n",
    "    \n",
    "    def lloyds(self):\n",
    "        centers = self.initialize()\n",
    "        self.assign(centers)\n",
    "        self.snaps.append(self.snap(centers))\n",
    "        \n",
    "        new_centers = self.calculate_new_centers()\n",
    "        while self.are_centers_diff(centers, new_centers):\n",
    "            centers = new_centers\n",
    "            self.unassign_all()\n",
    "            self.assign(centers)\n",
    "            new_centers = self.calculate_new_centers()\n",
    "        \n",
    "        return\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
